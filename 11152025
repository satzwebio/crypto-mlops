ğŸ§­ Project Overview

Goal:
Build a fully automated real-time crypto prediction MLOps pipeline using open-source tools on Kubernetes.
The flow:

WebSocket â†’ Kafka (micro-batch 60s) â†’ MinIO (raw parquet) â†’ Feast (offline + online) â†’ Kubeflow (train/eval) â†’ MLflow (track) â†’ DVC (version) â†’ BentoML/KServe (serve) â†’ Streamlit/Evidently (monitor)

âœ… Completed So Far
ğŸ—ï¸ Infrastructure Layer (infra namespace)

MinIO â€“ acts as the centralized S3-compatible storage for:

Raw crypto parquet data.

MLflow artifacts.

DVC remote storage.

PostgreSQL â€“ backend for Feast (offline store) and MLflow tracking DB.

Redis â€“ Feast online store for serving the most recent feature vectors.

MLflow â€“ deployed and connected with MinIO and PostgreSQL.

Kafka (Strimzi) â€“ deployed as a cluster with:

Internal (9092) and external (9094) listeners.

Configured NodePort and port-forwarding for external access.

Working topic: crypto-prices.

âš™ï¸ Feature Layer (feast_repo)

Feast repository configured with:

feature_store.yaml pointing to PostgreSQL (offline) and Redis (online).

Features defined for crypto prices (BTC/ETH).

Successfully materialized features into Redis.

Tested feature retrieval with Python.

ğŸ“¦ Data Management

DVC initialized and connected to MinIO (dvc-storage bucket).

Parquet data versioned and pushed successfully.

Verified artifacts and data appear in MinIO.

ğŸ”„ Data Streaming

Binance WebSocket producer (websocket_kafka_producer.py) working.

Successfully produces live BTCUSDT price updates to Kafka topic crypto-prices.

Verified Kafka consumer inside cluster receives messages.

Producer now containerized and ready for deployment in Kubernetes.

ğŸ§© Current Architecture

Namespaces

infra: for core services (Kafka, Redis, PostgreSQL, MinIO, MLflow).

crypto: for project workloads (producer, consumer, training, model serving).

Kafka communication

External access via NodePort 9094.

Local â†’ EC2 tunneling set up for testing.

Producer sends data â†’ Kafka topic â†’ consumer will persist to MinIO.

ğŸš€ Next Steps
ğŸ§± Phase 4: Data Pipeline (Kafka â†’ MinIO)

Goal: Consume from Kafka and store as parquet batches in MinIO.

Create kafka_consumer_to_minio.py (uses boto3 + confluent_kafka + pandas).

Run as a Kubernetes CronJob or Deployment in crypto namespace.

Output: raw files in minio://feast-feature-store/raw/YYYYMMDD/.

ğŸ§  Phase 5: Model Training (Kubeflow + MLflow + DVC)

Goal: Automate training and versioning.

Kubeflow pipeline reads parquet from MinIO.

Train models and log metrics/artifacts to MLflow.

DVC tracks model versions.

ğŸ§° Phase 6: Model Deployment (BentoML + KServe)

Goal: Serve latest approved model.

Package trained model with BentoML.

Deploy inference service on KServe.

Online feature store (Redis) supplies latest data.

ğŸ“Š Phase 7: Monitoring (Streamlit + Evidently)

Goal: Live dashboard and drift detection.

Streamlit displays predictions, metrics, and drift charts.

Evidently monitors data drift â†’ triggers retrain workflow in Kubeflow.

ğŸ” Next Immediate Action

We are currently at the â€œKafka â†’ MinIOâ€ ingestion step.
Next, weâ€™ll:

Write the consumer script.

Containerize and deploy it to the crypto namespace.

Verify parquet files landing in MinIO.